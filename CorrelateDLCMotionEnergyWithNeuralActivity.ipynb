{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1d0dfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b209ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPUTE MOTION ENERGY FROM DLC BODY VECTORS\n",
    "path = r'/Volumes/Behaviour 3/Bodyvectors_05_2000'\n",
    "\n",
    "bodies = [body for body in os.listdir(path) if body.endswith('bodyvectors_07_2000.csv')] # output from DLC analysis code\n",
    "\n",
    "# using the header from a trial where all 612 pre- and 632 post-stimulus frames passed the 0.5 likelihood to get\n",
    "# a list ranging from -612 to 632\n",
    "#correct = pd.read_csv(r'I:\\Data to test Aras 2P code\\Bodyvectors_07_2000\\2P05_Ses01_25OCT2021_approach_Trial_1_89009_bodyvectors_07_2000.csv')\n",
    "correct = pd.read_csv('/Volumes/Behaviour 3/Bodyvectors_05_2000/2P05_Ses01_25OCT2021_approach_Trial_1_89009_bodyvectors_07_2000.csv')\n",
    "cor_cols = list(correct.columns)\n",
    "\n",
    "b_motion = pd.DataFrame()\n",
    "b_motion2 = pd.DataFrame()\n",
    "\n",
    "bigcount = 0\n",
    "short_vectors = []\n",
    "shorter_vectors = []\n",
    "not_19 = []\n",
    "\n",
    "#the number of camera frames acquired during each 2P frame\n",
    "bins = [65,66,65,66,66,65,66,65,66,65,66,66,65,66,65,66,65,66,65]\n",
    "\n",
    "for body in bodies:\n",
    "    print('procesing: ', body)\n",
    "    if body.startswith('._'): # circumventing issues caused by invisible files on the external drive\n",
    "        continue\n",
    "      \n",
    "    b = pd.read_csv(os.path.join(path,body))\n",
    "    # insert NaN columns for the frames with likelihood <0.5 in order to have vectors of identical shape\n",
    "    if b.shape[1] < 1245:\n",
    "        length = b.shape[1]\n",
    "        print(length, 'bodyvector is short')\n",
    "        short_vectors.append([body, length])\n",
    "        smallcount = 0\n",
    "        cols = list(b.columns)\n",
    "        for c, cor_col in enumerate(cor_cols):\n",
    "            if cor_col in cols:\n",
    "                continue\n",
    "            else: \n",
    "                if int(cor_col) > 0:\n",
    "                    smallcount += 1 # counting the number of missing post-stimulus frames \n",
    "                b[cor_col]=np.nan\n",
    "    \n",
    "        print('smallcount: ', smallcount)\n",
    "        \n",
    "        if smallcount > 63: # skip trials that have more than 10 % of post-stimulus frames missing\n",
    "            print(body, ' doesnt have enough motion frames')\n",
    "            bigcount += 1\n",
    "            shorter_vectors.append([body, 1245-length, smallcount])\n",
    "            continue\n",
    "        b = b[cor_cols] \n",
    "        \n",
    "    b_mo = b.diff(axis=1).abs() # compute frame-wise motion energy\n",
    "    b_mo = b_mo.mean(axis=0) # calculate mean motion energy across body parts\n",
    "    b_mo[0] = np.nan # insert NaN column to maintain vector shape\n",
    "    print(b_mo.shape)\n",
    "    \n",
    "    a = 0\n",
    "    downsampled = []\n",
    "    for b in bins:\n",
    "        downsampled.append(b_mo.iloc[a:a+b].mean())\n",
    "        a = a + b\n",
    "        \n",
    "    if np.isnan(downsampled).any(): #not all trials had a sample for each bin. we might need to reduce the likelihood now?\n",
    "        print('Cannot use: there are not 19 bins')\n",
    "        not_19.append(body)\n",
    "        continue\n",
    "    else:\n",
    "        b_motion['motion_e'] = downsampled\n",
    "        entries = body.split('_')\n",
    "        identifier = entries[0]+'_'+entries[1]+'_'+entries[2]+'_'+entries[3]+'_'+entries[4]+'_'+entries[5]+'_'+entries[6]\n",
    "        b_motion['identifier'] = identifier\n",
    "        b_motion2 = pd.concat([b_motion2, b_motion], axis=0)\n",
    "\n",
    "b_motion2['frame'] = b_motion2.index\n",
    "print('number of short bodyvectors :', bigcount)\n",
    "short_bodyvectors = pd.DataFrame(short_vectors, columns=('trial', 'nb of frames')) # list of trials with any missing frame\n",
    "shorter_bodyvectors = pd.DataFrame(shorter_vectors, columns=('trial', 'total missing frames', 'post-stim missing frames')) # list of trials that were skipped because of >10% missing frames\n",
    "not_19 = pd.DataFrame(not_19)\n",
    "\n",
    "b_motion2.to_csv(os.path.join(path, 'body_motion_energy_05_2000.csv'))\n",
    "short_bodyvectors.to_csv(os.path.join(path, 'short_bodyvectors_05_2000.csv'))\n",
    "shorter_bodyvectors.to_csv(os.path.join(path, 'dropped_bodyvectors_05_2000.csv'))\n",
    "not_19.to_csv(os.path.join(path, 'not_19_05_2000.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa106095",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MATCH BODY MOTION ENERGY TO NEURAL ACTIVITY FOR EACH CELL AND FRAME SESSION-WISE\n",
    "motion = pd.read_csv(r'/Volumes/Behaviour 3/Bodyvectors_05_2000/body_motion_energy_05_2000.csv', index_col=0)\n",
    "\n",
    "input_path = r'/Volumes/Behaviour/Tailored 3sec 2P Trials'# dF_F0 traces cropped to 1.5 sec pre- and post-stimulus\n",
    "\n",
    "sessions = [session for session in os.listdir(input_path) if session.endswith('.csv')]\n",
    "\n",
    "pearsons = pd.DataFrame()\n",
    "session_names = []\n",
    "\n",
    "for session in sessions:\n",
    "    if session.startswith('._'): # circumventing issues with invisible files on external drives\n",
    "        continue\n",
    "    if session.endswith('2P05_Ses01.csv'): # excluding for the time being incomplete sessions (half-sessions)\n",
    "        continue\n",
    "    if session.endswith('2P05_Ses02.csv'):\n",
    "        continue\n",
    "    if session.endswith('2P07_Ses02.csv'):\n",
    "        continue\n",
    "    if session.endswith('2P11_Ses03.csv'):\n",
    "        continue\n",
    "    #if session.endswith('CFA.csv'): # excluding for the time being CFA sessions\n",
    "        #continue\n",
    "    \n",
    "    print('processing: ', session)\n",
    "    entries = session.split('_')\n",
    "    \n",
    "    if session.endswith('CFA.csv'): \n",
    "        ses_name = entries[3]+'_'+entries[4][:3]\n",
    "        \n",
    "    else:\n",
    "        ses_name = entries[3]+'_'+entries[4][:5]\n",
    "            \n",
    "    print(ses_name)\n",
    "    session_names.append(ses_name)\n",
    "    cells = pd.read_csv(os.path.join(input_path,session), index_col=0)\n",
    "    print('cells shape', cells.shape)\n",
    "    cell_list = (list(cells.columns)) # list of rois \n",
    "    cell_list = cell_list[:-1] # last column is the identifier, hence I remove it\n",
    "    session_mo = motion[motion['identifier'].str.contains(str(ses_name))] # subsetting body motion energy file to the session being processed\n",
    "    print('session_mo shape', session_mo.shape)# subsetting body motion energy file to the session being processed\n",
    "    session_mo['ids']  = session_mo.apply(lambda x: x['identifier'] +'_'+str(x['frame']), axis=1) # creating a new identifier column which combines trial ID and frame number\n",
    "    # now I have to create a matching frames_for_each_trial column for the 2P recording dataframe\n",
    "    frames_template = np.array([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]) # template with the number of frames per trial\n",
    "    factor = int(cells.shape[0]/19) # finding out how many trials per session there are (this is not always identical to the motion energy file, due to the likelyhood threshold)\n",
    "    cells['frame'] = np.tile(frames_template, factor) # distritbute 'frames_template' across the whole 2P recording\n",
    "    cells['ids'] = cells.apply(lambda x: x['identifier'] +'_'+str(x['frame']), axis=1) # create new identifier column as in line 34\n",
    "    temp = pd.merge(cells, session_mo, on=\"ids\") # creating a temporary data frame by merging motion energy vectors and 2P traces aligned on 'ids' column  \n",
    "    temp = temp.dropna()   # then dropping those frames that don't have motion energy values due to likelihood threshold       \n",
    "    \n",
    "    li = []\n",
    "    for c in cell_list: # for each cell in a session, compute Pearsons' r by correlating with motion energy\n",
    "        P,_ = pearsonr(temp[c],temp['motion_e'])\n",
    "        li.append((c, P))\n",
    "    \n",
    "    corr = pd.DataFrame(li, columns=('cell_id', 'pearsons'))\n",
    "    \n",
    "    pearsons = pd.concat([pearsons, corr], axis = 0)\n",
    "\n",
    "pearsons.to_csv(os.path.join(path, 'pearsons_long_05_2000.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62757df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make correlation plots off the long-format data-frame\n",
    "output_path = '/Volumes/Behaviour/Tailored 3sec 2P Trials/Motion Correlation Plots'\n",
    "\n",
    "for s in session_names:\n",
    "    print(s)\n",
    "    df = pearsons[pearsons['cell_id'].str.contains(str(s))]\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.scatter(x=df['cell_id'], y=df['pearsons'], alpha = 0.5)\n",
    "    plt.ylim((-0.2,0.5))\n",
    "    plt.show()\n",
    "    #plt.savefig(os.path.join(output_path, s+'_motion_correlation_05.png'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
